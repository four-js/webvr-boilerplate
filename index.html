<!DOCTYPE html>

<html lang="en">
<head>
<title>Web VR boilerplate (Cardboard and Oculus)</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<meta name="mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
<style>
body {
  width: 100%;
  height: 100%;
  position: fixed;
  background-color: #000;
  color: #fff;
  margin: 0px;
  padding: 0;
  overflow: hidden;
}
</style>
</head>

<body>

</body>

<!--
  three.js 3d library
  -->
<script src="js/deps/three.js"></script>

<!--
  VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
   -->
<script src="js/deps/VRControls.js"></script>

<!--
  VREffect.js handles stereo camera setup and rendering.
  -->
<script src="js/deps/VREffect.js"></script>

<!--
  A polyfill for WebVR using the Device{Motion,Orientation}Event API.
  -->
<script src="js/deps/webvr-polyfill.js"></script>

<!--
  Helps enter and exit VR mode, provides best practices while in VR.
  -->
<script src="build/webvr-manager.js"></script>

<script>
/*
 * Debug parameters.
 */

// Enable distortion everywhere.
//WEBVR_FORCE_DISTORTION = true;
// Override the distortion background color.
//WEBVR_BACKGROUND_COLOR = new THREE.Vector4(1, 0, 0, 1);
// Change the tracking prediction mode.
//WEBVR_PREDICTION_MODE = 2;
// In prediction mode, change how far into the future to predict.
//WEBVR_PREDICTION_TIME_MS = 100;
</script>

<script id="vs" type="x-shader/x-vertex">

  uniform sampler2D map;

  uniform float width;
  uniform float height;
  uniform float nearClipping, farClipping;

  uniform float pointSize;
  uniform float zOffset;

  varying vec2 vUv;

  const float XtoZ = 1.11146; // tan( 1.0144686 / 2.0 ) * 2.0;
  const float YtoZ = 0.83359; // tan( 0.7898090 / 2.0 ) * 2.0;

  void main() {

    vUv = vec2( position.x / width, position.y / height );

    vec4 color = texture2D( map, vUv );
    float depth = ( color.r + color.g + color.b ) / 3.0;

    // Projection code by @kcmic

    float z = ( 1.0 - depth ) * (farClipping - nearClipping) + nearClipping;

    vec4 pos = vec4(
      ( position.x / width - 0.5 ) * z * XtoZ,
      ( position.y / height - 0.5 ) * z * YtoZ,
      - z + zOffset,
      1.0);

    gl_PointSize = pointSize;
    gl_Position = projectionMatrix * modelViewMatrix * pos;

  }

</script>

<script id="fs" type="x-shader/x-fragment">

  uniform sampler2D map;

  varying vec2 vUv;

  void main() {

    vec4 color = texture2D( map, vUv );
    gl_FragColor = vec4( color.r, color.g, color.b, 0.2 );

  }

</script>

<script>

function setupScene(scene, renderer) {
  // LIGHTS

  ambientLight = new THREE.AmbientLight( 0x444444 );
  scene.add( ambientLight );

  //

  pointLight = new THREE.PointLight( 0xffffff, 1.5, 1000 );
  pointLight.color.setHSL( 0.05, 1, 0.95 );
  pointLight.position.set( 0, 0, 600 );

  scene.add( pointLight );

  // shadow for PointLight

  spotLight = new THREE.SpotLight( 0xffffff, 1.5 );
  spotLight.position.set( 0.05, 0.05, 1 );
  spotLight.color.setHSL( 0.6, 1, 0.95 );
  scene.add( spotLight );

  spotLight.position.multiplyScalar( 700 );

  spotLight.castShadow = true;
  spotLight.onlyShadow = true;
  // spotLight.shadowCameraVisible = true;

  spotLight.shadowMapWidth = 2048;
  spotLight.shadowMapHeight = 2048;

  spotLight.shadowCameraNear = 200;
  spotLight.shadowCameraFar = 1500;

  spotLight.shadowCameraFov = 40;

  spotLight.shadowBias = -0.005;
  spotLight.shadowDarkness = 0.35;

  //

  directionalLight = new THREE.DirectionalLight( 0xffffff, 1.5 );
  directionalLight.position.set( 1, -0.5, 1 );
  directionalLight.color.setHSL( 0.6, 1, 0.95 );
  scene.add( directionalLight );

  directionalLight.position.multiplyScalar( 500 );

  directionalLight.castShadow = true;
  // directionalLight.shadowCameraVisible = true;

  directionalLight.shadowMapWidth = 2048;
  directionalLight.shadowMapHeight = 2048;

  directionalLight.shadowCameraNear = 200;
  directionalLight.shadowCameraFar = 1500;

  directionalLight.shadowCameraLeft = -500;
  directionalLight.shadowCameraRight = 500;
  directionalLight.shadowCameraTop = 500;
  directionalLight.shadowCameraBottom = -500;

  directionalLight.shadowBias = -0.005;
  directionalLight.shadowDarkness = 0.35;

  //

  directionalLight2 = new THREE.DirectionalLight( 0xffffff, 1.2 );
  directionalLight2.position.set( 1, -0.5, -1 );
  directionalLight2.color.setHSL( 0.08, 1, 0.825 );
  scene.add( directionalLight2 );

  var mapHeight = THREE.ImageUtils.loadTexture( "obj/leeperrysmith/Infinite-Level_02_Disp_NoSmoothUV-4096.jpg" );

  mapHeight.anisotropy = 4;
  mapHeight.repeat.set( 0.998, 0.998 );
  mapHeight.offset.set( 0.001, 0.001 );
  mapHeight.wrapS = mapHeight.wrapT = THREE.RepeatWrapping;
  mapHeight.format = THREE.RGBFormat;

  var material = new THREE.MeshPhongMaterial( { color: 0x552811, specular: 0x333333, shininess: 25, bumpMap: mapHeight, bumpScale: 19, metal: false } );

  loader = new THREE.JSONLoader();
  loader.load( "obj/leeperrysmith/LeePerrySmith.js", function( geometry ) { 
    mesh = new THREE.Mesh( geometry, material );

    mesh.position.y = - 50;
    scale = 100;
    mesh.scale.set( scale, scale, scale );

    mesh.castShadow = true;
    mesh.receiveShadow = true;

    scene.add( mesh );

   } );

  // 
  renderer.shadowMap.enabled = true;
  renderer.shadowMap.cullFace = THREE.CullFaceBack;

  //
  renderer.gammaInput = true;
  renderer.gammaOutput = true;
}

//Setup three.js WebGL renderer
var renderer = new THREE.WebGLRenderer({ antialias: false });
renderer.setPixelRatio(window.devicePixelRatio);

// Append the canvas element created by the renderer to document body element.
document.body.appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.3, 10000);

// Apply VR headset positional data to camera.
var controls = new THREE.VRControls(camera);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(window.innerWidth, window.innerHeight);

// Create a VR manager helper to enter and exit VR mode.
var manager = new WebVRManager(renderer, effect, {hideButton: false});

setupScene(scene, renderer);

// Request animation frame loop function
function animate(timestamp) {
  // Apply rotation to cube mesh

  // Update VR headset position and apply to camera.
  controls.update();

  // Render the scene through the manager.
  manager.render(scene, camera, timestamp);

  requestAnimationFrame(animate);
}

// Kick off animation loop
animate();

// Reset the position sensor when 'z' pressed.
function onKey(event) {
  if (event.keyCode == 90) { // z
    controls.resetSensor();
  }
};

window.addEventListener('keydown', onKey, true);

// Handle window resizes
function onWindowResize() {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();

  effect.setSize(window.innerWidth, window.innerHeight);
}

window.addEventListener('resize', onWindowResize, false);

</script>

</html>
